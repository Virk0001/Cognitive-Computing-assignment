{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCimhM9xweRg"
      },
      "outputs": [],
      "source": [
        "# Assignment 3\n",
        "# Q1 Create a dataset as follow in the table.\n",
        "\n",
        "dataSet = {\n",
        "    \"Tid\":[1,2,3,4,5,6,7,8,9,10],\n",
        "    \"Refund\":[\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\"],\n",
        "    \"Marital Status\":[\"Single\",\"Married\",\"Single\",\"Married\",\"Divorced\",\"Married\",\"Divorced\",\"Single\",\"Married\",\"Single\"],\n",
        "    \"Taxable Income (K)\": [125,100,70,120,95,60,220,85,75,90],\n",
        "    \"Cheat\": [\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\"]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWm8pd0Sw08C",
        "outputId": "f0b1efd8-5b11-4159-b5f5-18f29b8f9d27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Tid Refund Marital Status  Taxable Income (K) Cheat\n",
            "0    1    Yes         Single                 125    No\n",
            "1    2     No        Married                 100    No\n",
            "2    3     No         Single                  70    No\n",
            "3    4    Yes        Married                 120    No\n",
            "4    5     No       Divorced                  95   Yes\n",
            "5    6     No        Married                  60    No\n",
            "6    7    Yes       Divorced                 220    No\n",
            "7    8     No         Single                  85   Yes\n",
            "8    9     No        Married                  75    No\n",
            "9   10     No         Single                  90   Yes\n",
            "\n",
            "Tid                        1\n",
            "Refund                   Yes\n",
            "Marital Status        Single\n",
            "Taxable Income (K)       125\n",
            "Cheat                     No\n",
            "Name: 0, dtype: object\n",
            "\n",
            "Tid                          5\n",
            "Refund                      No\n",
            "Marital Status        Divorced\n",
            "Taxable Income (K)          95\n",
            "Cheat                      Yes\n",
            "Name: 4, dtype: object\n",
            "\n",
            "Tid                        8\n",
            "Refund                    No\n",
            "Marital Status        Single\n",
            "Taxable Income (K)        85\n",
            "Cheat                    Yes\n",
            "Name: 7, dtype: object\n",
            "\n",
            "Tid                         9\n",
            "Refund                     No\n",
            "Marital Status        Married\n",
            "Taxable Income (K)         75\n",
            "Cheat                      No\n",
            "Name: 8, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Q2 From the above table that you have created, locate row 0, 4, 7 and 8 using DataFrame\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "dataSet = {\n",
        "    \"Tid\":[1,2,3,4,5,6,7,8,9,10],\n",
        "    \"Refund\":[\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\"],\n",
        "    \"Marital Status\":[\"Single\",\"Married\",\"Single\",\"Married\",\"Divorced\",\"Married\",\"Divorced\",\"Single\",\"Married\",\"Single\"],\n",
        "    \"Taxable Income (K)\": [125,100,70,120,95,60,220,85,75,90],\n",
        "    \"Cheat\": [\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\"]\n",
        "}\n",
        "\n",
        "myDataFrame = pd.DataFrame(dataSet)\n",
        "print(myDataFrame)\n",
        "print()\n",
        "print(myDataFrame.iloc[0])\n",
        "print()\n",
        "print(myDataFrame.iloc[4])\n",
        "print()\n",
        "print(myDataFrame.iloc[7])\n",
        "print()\n",
        "print(myDataFrame.iloc[8])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkAJR8rrxAdC",
        "outputId": "cd466151-1f42-4b29-b168-d34c0fae09a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.11/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.6.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.1.8)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle->opendatasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle->opendatasets) (3.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: https://www.kaggle.com/gurshersingh0\n",
            "Your Kaggle Key:"
          ]
        }
      ],
      "source": [
        "# Q.3 Navigate the DataFrame and do the following task for the table created in question 1:\n",
        "# 1.\tSelect row from index 3 to 7.\n",
        "# 2.\tSelect row from index 4 to 8, and column 2 to 4.\n",
        "# 3.\tSelect all rows with column index 1 to 3 (include index 3 during selection).\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "dataSet = {\n",
        "    \"Tid\":[1,2,3,4,5,6,7,8,9,10],\n",
        "    \"Refund\":[\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\"],\n",
        "    \"Marital Status\":[\"Single\",\"Married\",\"Single\",\"Married\",\"Divorced\",\"Married\",\"Divorced\",\"Single\",\"Married\",\"Single\"],\n",
        "    \"Taxable Income (K)\": [125,100,70,120,95,60,220,85,75,90],\n",
        "    \"Cheat\": [\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\"]\n",
        "}\n",
        "\n",
        "myDataFrame = pd.DataFrame(dataSet)\n",
        "\n",
        "myDataFrame.iloc[3:8]\n",
        "\n",
        "myDataFrame.iloc[4:9,2:5]\n",
        "\n",
        "# Q.3 Navigate the DataFrame and do the following task for the table created in question 1:\n",
        "# 1.\tSelect row from index 3 to 7.\n",
        "# 2.\tSelect row from index 4 to 8, and column 2 to 4.\n",
        "# 3.\tSelect all rows with column index 1 to 3 (include index 3 during selection).\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "dataSet = {\n",
        "    \"Tid\":[1,2,3,4,5,6,7,8,9,10],\n",
        "    \"Refund\":[\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\"],\n",
        "    \"Marital Status\":[\"Single\",\"Married\",\"Single\",\"Married\",\"Divorced\",\"Married\",\"Divorced\",\"Single\",\"Married\",\"Single\"],\n",
        "    \"Taxable Income (K)\": [125,100,70,120,95,60,220,85,75,90],\n",
        "    \"Cheat\": [\"No\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\"]\n",
        "}\n",
        "\n",
        "myDataFrame = pd.DataFrame(dataSet)\n",
        "\n",
        "myDataFrame.iloc[3:8]\n",
        "\n",
        "myDataFrame.iloc[4:9,2:5]\n",
        "\n",
        "myDataFrame.iloc[:,1:4]\n",
        "\n",
        "!pip install opendatasets\n",
        "\n",
        "!pip install pandas\n",
        "\n",
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "\n",
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "\n",
        "od.download(\"https://www.kaggle.com/datasets/uciml/iris\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhHYuhl5xKnL"
      },
      "outputs": [],
      "source": [
        "# Q.4\tRead a csv file and display its first five rows.\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"./iris/Iris.csv\")\n",
        "\n",
        "df.iloc[0:6]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyyAC-WVx67w"
      },
      "outputs": [],
      "source": [
        "# Q.5\tFrom the csv file (uploaded in the Q.4) delete row 4, and delete column 3. Display the result.\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"./iris/Iris.csv\")\n",
        "df.drop(index=3,inplace=True)\n",
        "df.drop(columns=\"PetalLengthCm\",inplace=True)\n",
        "df\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvP3fVfdyCY3"
      },
      "outputs": [],
      "source": [
        "# Q.6\tCreate a sample dataset (employees.csv) containing information about employees in a company\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"EmployeeDetails.csv\")\n",
        "\n",
        "#a)\tShape (number of rows and columns) of the DataFrame.\n",
        "df.shape\n",
        "\n",
        "#b)\tSummary of the DataFrame that includes the data types and non-null counts for each column.\n",
        "df.info()\n",
        "\n",
        "#c)\tGenerate descriptive statistics.\n",
        "df.describe()\n",
        "\n",
        "#d)\tDisplay the first 5 rows and last 3 rows of the dataset.\n",
        "df.head(5)\n",
        "df.tail(3)\n",
        "\n",
        "# e)\tCalculate the following statistics from the dataset:\n",
        "# i.\tThe average salary of employees.\n",
        "# ii.\tThe total bonus paid to all employees.\n",
        "# iii. The youngest employee's age.\n",
        "# iv. The highest performance rating\n",
        "\n",
        "df['Salary '].mean()\n",
        "df['Bonus '].sum()\n",
        "df['Age '].min()\n",
        "df['Rating '].max()\n",
        "\n",
        "\n",
        "# f)\tSort the DataFrame by the Salary column in descending order.\n",
        "df.sort_values(by='Salary ', ascending=True, inplace=True)\n",
        "\n",
        "#g)\tAdd a new column that categorizes employees based on their performance rating:\n",
        "# i.\tExcellent for ratings >= 4.5\n",
        "# ii.\tGood for ratings >= 4.0 but < 4.5\n",
        "# iii.\tAverage for ratings < 4.0\n",
        "\n",
        "def categorize_performance(rating):\n",
        "    if rating >= 4.5:\n",
        "        return 'Excellent'\n",
        "    elif 4.0 <= rating < 4.5:\n",
        "        return 'Good'\n",
        "    else:\n",
        "        return 'Average'\n",
        "\n",
        "df['Performance_Category'] = df['Rating '].apply(categorize_performance)\n",
        "\n",
        "# h)\tIdentify missing values in the DataFrame. (DOUBT)\n",
        "nullers = df.isnull().sum()\n",
        "print(nullers)\n",
        "\n",
        "# i)\tRename the Employee_ID column to ID.\n",
        "print(df.columns)\n",
        "df.rename(columns={'Employee_ID ':\"ID\"},inplace=True)\n",
        "\n",
        "\n",
        "#j)\tFind all employees who:\n",
        "# i.\tHave more than 5 years of experience.\n",
        "# ii.\tBelong to the IT department.  (DOUBT)\n",
        "\n",
        "df_v2 = df[(df['Years_of_Experience '] > 5) & (df['Department '] == 'IT')]\n",
        "df_v2.head(2)\n",
        "\n",
        "# k)\tModify the dataset by adding a new column, Tax, which deducts 10% of the Salary.\n",
        "df['Tax'] = df['Salary '] * 0.10\n",
        "\n",
        "\n",
        "# l)\tSave the modified DataFrame (with added columns) to a new CSV file.\n",
        "df.to_csv('new_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhC263B9yL8G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}